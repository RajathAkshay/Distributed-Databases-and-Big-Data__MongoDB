{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA VISUALISATION- Static and Streaming <hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Visualisation part will deal with getting useful insights from the data. this is essential when the load of the data is enormous and aggregation and showcasing the data in human readable and understandable format is quintessential. The Data Visualization is divided into 2 parts:\n",
    "<ol>\n",
    "        <li><b>Streaming Data Visualisation</b> : This part of Visualization will be useful for plotting the streamed data as and when it is streamed for climate data and showcase insights in terms of highest and lowest air temperatures for the streamed data</li>\n",
    "    <li><b>Static Data Visualisation</b> : This part of Visualisationis responsible for plotting and extracting insights from the data already stored in the database. This task involves querying the database and plotting visualisations. The first one being plotting the top 10 number of fires with respect to time and the second one plotting the occurences of the fires by making use of latitude and longitude information from the data partitions stored in the database and plot them on a map. We will also provide addtional information in terms of air temperature, relative humidity, surface temperature and confidence. These will be shown on hovering over the tagged location markers on the map.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Streaming Visualisation <hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from time import sleep\n",
    "from kafka import KafkaConsumer\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "# topic for the visualiser to connect to. the visualiser will consume data from the streamed to this topic\n",
    "topic = 'test'\n",
    "\n",
    "# function to annotate maximum point in the streamed partition of data\n",
    "def annotate_max(x, y, ax = None):\n",
    "    ymax = max(y)\n",
    "    xpos = y.index(ymax)\n",
    "    xmax = x[xpos]\n",
    "    text = 'Max: Time={}, Value={}'.format(xmax, ymax)\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "    ax.annotate(text, xy=(xmax, ymax), xytext=(xmax, ymax+5), arrowprops=dict(facecolor='red', shrink=0.05),)\n",
    "    \n",
    "# function to annotate the minimum point in the streamed partition of data\n",
    "def annotate_min(x, y, ax = None):\n",
    "    ymin = min(y)\n",
    "    xpos = y.index(ymin)\n",
    "    xmin = x[xpos]\n",
    "    text = 'Min: Time={}, Value={}'.format(xmin, ymin)\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "    ax.annotate(text, xy=(xmin, ymin), xytext=(xmin, ymin+5), arrowprops=dict(facecolor='orange', shrink=0.05),)\n",
    "\n",
    "# function to connect to the kafka server instance and return the instance of the kafka consumer. this instance will be used\n",
    "# passed to consume message function to parse the messages and pass the parsed messages to the visualiser\n",
    "def connect_kafka_consumer():\n",
    "    _consumer = None\n",
    "    try:\n",
    "         _consumer = KafkaConsumer(topic,\n",
    "                                   consumer_timeout_ms=10000, # stop iteration if no message after 10 sec\n",
    "                                   # auto_offset_reset='earliest', # comment this if you don't want to consume earliest available message\n",
    "                                   bootstrap_servers=['localhost:9092'],\n",
    "                                   api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _consumer\n",
    "\n",
    "# function to create a container with specified shape and size. this container will be used to plot various data points \n",
    "# and showcase points of interest.\n",
    "def init_plots():\n",
    "    try:\n",
    "        width = 9.5\n",
    "        height = 6\n",
    "        fig = plt.figure(figsize=(width,height)) # create new figure\n",
    "        #fig.subplots_adjust(hspace=0.8)\n",
    "        # ax = fig.add_subplot(111) # adding the subplot axes to the given grid position\n",
    "        ax2 = fig.add_subplot(111)\n",
    "        ax2.set_xlabel('Time')\n",
    "        ax2.set_ylabel('Air temperature')\n",
    "        ax2.title.set_text('Arrival Time Vs Air temperature')\n",
    "        fig.suptitle('Real-time uniform stream data visualization with interesting points') # giving figure a title\n",
    "        fig.show() # displaying the figure\n",
    "        fig.canvas.draw() # drawing on the canvas\n",
    "        return fig, ax2\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "    \n",
    "# function to consume the messages recieved from the producer from the specified stream.\n",
    "def consume_messages(consumer, fig, ax2):\n",
    "    try:\n",
    "        # container for x and y values\n",
    "        x2, y2 = [], []\n",
    "        # print('Waiting for messages')\n",
    "        for message in consumer:\n",
    "            \n",
    "            # converting the read partition from string to a dictionary to check whether the data chunk belongs to Producer 1.\n",
    "            # this is important because we are publishing data from all the producers to a single topic and streaming from the same topic.\n",
    "            # therefore we have to filter data from only produer1 to plot the insights desired.\n",
    "            each_clim = ast.literal_eval(message.value.decode('utf-8')) \n",
    "            if each_clim[\"sender_id\"] == \"climate_producer_1\":\n",
    "                temp = each_clim[\"air_temperature_celcius\"]\n",
    "                \n",
    "                # appeding arrival time for each data partition\n",
    "                x2.append(dt.datetime.now().strftime(\"%X\")) \n",
    "                \n",
    "                # appending air temperature from the extracted data chunk to list\n",
    "                y2.append(temp)\n",
    "                \n",
    "                # we will start producing plots if the number of recieved chunks exceeds 5 so that it gives a moving functionality\n",
    "                if len(y2)>5:\n",
    "                    ax2.clear()\n",
    "                    \n",
    "                    # producing a line plot for list of values attained previously\n",
    "                    ax2.plot(x2, y2, color=\"green\")\n",
    "                    # ax2.plot(x2, y2)\n",
    "                    ax2.set_xlabel('Arrival Time')\n",
    "                    ax2.set_ylabel('Air temperature')\n",
    "                    ax2.set_title('Arrival Time Vs Value')\n",
    "                    ax2.set_ylim(0,100) \n",
    "                    ax2.set_yticks([0,20,40,60,80,100])\n",
    "                    \n",
    "                    # calling the maximum and minimum function to annotate data points in the streaming plot\n",
    "                    annotate_max(x2, y2, ax2)\n",
    "                    annotate_min(x2, y2, ax2)\n",
    "\n",
    "                    fig.canvas.draw()\n",
    "                    \n",
    "                    # removing the item in the first position\n",
    "                    x2.pop(0) \n",
    "                    y2.pop(0)\n",
    "        plt.close('all')\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Getting an instance of the kafka consumer\n",
    "    consumer = connect_kafka_consumer()\n",
    "    \n",
    "    # initiate the container for plot\n",
    "    fig, ax2 = init_plots()\n",
    "    \n",
    "    # call the consume message to plot the streamed data in the initiated canvas.\n",
    "    consume_messages(consumer, fig, ax2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Static Visualisation <hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the essential libraries. \n",
    "import matplotlib.pyplot as pyplt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import webbrowser\n",
    "from pymongo import MongoClient\n",
    "import gmplot\n",
    "# Googleâ€™s geocoding service enabling map initilization to the location of your choice.\n",
    "gmap = gmplot.GoogleMapPlotter(-37.812015244225677, 144.951471202974, 15) # latitude and longitude of melbourne city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Top 10 Fires - Records with the top 10 number of fires. Plot a bar chart with time as the x-axis and number of fires as the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating mongo client.\n",
    "client = MongoClient()\n",
    "\n",
    "# instantiating the database\n",
    "db = client.assignment2\n",
    "\n",
    "# instantiating the collections in the created database.\n",
    "fire = db.fire\n",
    "climate = db.climate\n",
    "\n",
    "# Preparing the data for plotting\n",
    "unoccupiedList = []\n",
    "\n",
    "# aggregate the fire data to count the number of plots in a given time.\n",
    "results = fire.aggregate(\n",
    "    [\n",
    "        {\"$group\":{\n",
    "            \"_id\":\"$datetime\", \"count\":{\"$sum\":1}\n",
    "        }\n",
    "        },\n",
    "        {\"$sort\": {\"count\":-1}}\n",
    "        ,\n",
    "        {\"$limit\":10}])\n",
    "\n",
    "# store the output.\n",
    "res = [x for x in results]\n",
    "\n",
    "# use two list to store the plot data.\n",
    "time = []\n",
    "no_of_fire = []\n",
    "for each in res:\n",
    "    time.append(str(each[\"_id\"].time())) # extract just the time stamp for plotting. \n",
    "    no_of_fire.append(int(each[\"count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use of matplotlib.pyplot to plot top 10 fires.\n",
    "index = np.arange(len(time))\n",
    "pyplt.bar(index,no_of_fire)\n",
    "pyplt.xlabel('Time',fontsize= 10)\n",
    "pyplt.ylabel('Number of Fires',fontsize=10)\n",
    "pyplt.xticks(index,time,fontsize=10,rotation=30)\n",
    "pyplt.title('Top 10 Number of fires',fontsize=20)\n",
    "pyplt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "pyplt.figure(figsize=[10,10])\n",
    "pyplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Plot fire locations in the map with air temperature, surface temperature, relative humidity and confidence. See the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the latitude and longitude in a list.\n",
    "lat = []\n",
    "lon = []\n",
    "\n",
    "# using aggregate function to join both the collections.\n",
    "res = fire.aggregate([{\n",
    "    \"$lookup\":\n",
    "    {\n",
    "        \"from\": \"climate\",\n",
    "        \"localField\": \"date\",\n",
    "        \"foreignField\": \"date\",\n",
    "        \"as\":\"climate\"\n",
    "    }},\n",
    "    {\"$project\":{\"surface_temperature_celcius\":1,\"confidence\":1,\"latitude\":1,\"longitude\":1,\"climate\" : \n",
    "               { \"air_temperature_celcius\":1,\"relative_humidity\":1}}},\n",
    "    {\"$unwind\": \"$climate\"}\n",
    "    ])\n",
    "\n",
    "# storing the output in a variable \n",
    "res = [x for x in res]\n",
    "\n",
    "\n",
    "#Looping through all the data to add markers\n",
    "for row in res:\n",
    "    title_str = \"relative humidity:\"+ str(row[\"climate\"][\"relative_humidity\"]) +\",\"+ \" surf-temp:\"+str(row[\"surface_temperature_celcius\"])+\",\"+\" air-temp:\"+str(row[\"climate\"][\"air_temperature_celcius\"])+\",\"+\" confidence:\"+str(row[\"confidence\"]) \n",
    "    gmap.marker(row[\"latitude\"],row[\"longitude\"],title = title_str)\n",
    "    lat.append(float(row['latitude'])) # storing latitude in a list\n",
    "    lon.append(float(row['longitude'])) # storing longitude in a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the points on the map\n",
    "gmap.scatter(lat,lon, '#FF4500', size=10, marker=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing the map\n",
    "gmap.draw(\"Fire_location.html\")\n",
    "\n",
    "# opens the html document.\n",
    "webbrowser.open_new(\"Fire_location.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
